Ah lÃ  tu touches Ã  du **lourd pour la modÃ©lisation rapide et performante** !  
### ğŸš€ `LightGBM` = Light Gradient Boosting Machine

---

## ğŸ” Câ€™est quoi LightGBM ?

**LightGBM** est une **librairie de machine learning** open-source dÃ©veloppÃ©e par **Microsoft**.  
Elle implÃ©mente lâ€™algorithme **gradient boosting** de faÃ§on **ultra-optimisÃ©e**, notamment pour les gros datasets.

### âœ… Câ€™est lâ€™une des meilleures librairies pour :
- ğŸ”® **Classification / RÃ©gression**
- ğŸ“ˆ **Ranking (ex. moteur de recherche)**
- ğŸ§  Features trÃ¨s hautement catÃ©goriques
- ğŸï¸ GÃ©rer des **millions de lignes avec peu de RAM**
- ğŸ§ª Gagner des **compÃ©titions Kaggle** (elle est adorÃ©e lÃ -bas)

---

## âš™ï¸ Pourquoi LightGBM est rapide ?

| Optimisation | Description |
|--------------|-------------|
| **Histogram-based** | Regroupe les valeurs en bins pour accÃ©lÃ©rer les splits |
| **Leaf-wise growth** | Lâ€™arbre se dÃ©veloppe selon la *meilleure perte* plutÃ´t que par niveau |
| **Support du multi-thread** | Exploite plusieurs cÅ“urs CPU |
| **Support GPU** | Pour de gros jeux de donnÃ©es |

---

## ğŸ“¦ Installation

```bash
pip install lightgbm
```

Pour GPU :
```bash
pip install lightgbm --install-option=--gpu
# ou mieux : compiler depuis source avec CUDA
```

---

## ğŸ” Exemple rapide dâ€™utilisation avec Pandas

```python
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import pandas as pd

# Exemple fictif
df = pd.read_csv("flights.csv")
df = df[df["duration_minutes"] < 1000]

X = df[["duration_minutes"]]  # ou plus de features
y = (df["duration_minutes"] > 300).astype(int)  # prÃ©dire si vol long

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)

train_data = lgb.Dataset(X_train, label=y_train)
val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)

params = {
    "objective": "binary",
    "metric": "binary_logloss",
    "verbosity": -1
}

model = lgb.train(params, train_data, valid_sets=[val_data], num_boost_round=100, early_stopping_rounds=10)

# PrÃ©dictions
y_pred = model.predict(X_val)
y_pred_labels = (y_pred > 0.5).astype(int)
print("Accuracy:", accuracy_score(y_val, y_pred_labels))
```

---

## ğŸ§  Pour aller plus loin :

- Compatible avec **scikit-learn API** : `lgb.LGBMClassifier()`, etc.
- GÃ¨re les **valeurs manquantes**, les **catÃ©gories**, les **poids**
- TrÃ¨s utilisÃ© en production (trÃ¨s stable)
- Peut Ãªtre **interprÃ©tÃ©** (via SHAP ou `plot_importance`)
- Autres librairies comme XGBoost ou CatBoost 

---

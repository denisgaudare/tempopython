### üß† Strat√©gie hybridation :
"""
**Parties CPU-intensives** ‚Üí utilisent plusieurs **processus** (`multiprocessing`)
**Parties I/O-intensives** (ex : requ√™tes web, lecture fichiers r√©seau) ‚Üí utilisent **asyncio**

### ‚úÖ Exemple concret :

Imaginons un script qui :
1. Charge des fichiers JSON distants (I/O)
2. Fait un gros traitement math√©matique sur chaque (CPU)
3. Sauvegarde les r√©sultats (I/O)
"""

### üì¶ Code hybride

import asyncio
#import aiohttp
import json
from multiprocessing import Pool, cpu_count

# === Partie CPU (calcul intensif) ===

def analyse_json(data):
    # Simulation de calcul lourd
    total = sum(x**2 for x in data["values"])
    return {"id": data["id"], "score": total}

# === Partie I/O (chargement fichiers) ===

def fetch_json(session, url):
    pass

def download_all(urls):
    pass

# === Orchestration g√©n√©rale ===

def main():
    urls = [
        "https://jsonplaceholder.typicode.com/comments",
        "https://jsonplaceholder.typicode.com/users"
    ] * 10

    # √âtape 1 : Download des fichiers en parall√®le (I/O avec asyncio)

    # √âtape 2 : Traitement CPU en parall√®le (multiprocessing)

    # √âtape 3 : Sauvegarde (I/O, ici simul√©e)

if __name__ == "__main__":
    main()
"""
### üí° Points cl√©s :
- `asyncio.run(...)` pour lancer le code asynchrone (I/O)
- `Pool.map(...)` pour parall√©liser le calcul CPU
- On **√©vite de m√©langer** asyncio et multiprocessing dans le m√™me thread/process
- Les donn√©es JSON sont d‚Äôabord collect√©es, puis trait√©es

- Bonus1 : Combiner avec **ThreadPoolExecutor** pour du I/O bloquant (genre acc√®s fichiers, DB)
- Bonus2 : D√©couper le pipeline avec un **scheduler** (ex : `concurrent.futures`, `ray`, ou `dask`)
"""

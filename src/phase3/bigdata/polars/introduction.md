# ðŸ¦¾ **Introduction Ã  Polars**  
*Une alternative moderne Ã  Pandas, boostÃ©e par Rust*

---

## ðŸ“š 1. Pourquoi Polars ?  

### âš™ï¸ Limitations de Pandas :
- Monothread (soumis au GIL)
- Consommation mÃ©moire importante
- Performance parfois dÃ©cevante sur gros volumes
- Pas de lazy evaluation

### ðŸš€ Polars, câ€™est :
- Ã‰crit en **Rust** â†’ ultra-performant
- **Multithread** par dÃ©faut
- Ã‰valuation **lazy** possible (comme Spark)
- API Python inspirÃ©e de Pandas + SQL-like
- CompatibilitÃ© avec Arrow / Parquet

---

## ðŸ§° 2. Installation

```bash
pip install polars
```

Optionnel :
```bash
pip install pyarrow
```

---

## ðŸ”¤ 3. Syntaxe de base vs Pandas

### ðŸ“„ CrÃ©ation de DataFrame

```python
import polars as pl

df = pl.DataFrame({
    "name": ["Alice", "Bob"],
    "age": [25, 32],
})
```

### ðŸ”Ž SÃ©lection de colonnes

```python
df["age"]           # Serie
df.select("name")   # DataFrame
df.select(["age", "name"])
```

### ðŸ“Š Filtres

```python
df.filter(pl.col("age") > 30)
```

### ðŸ” GroupBy

```python
df.groupby("name").agg(pl.col("age").mean())
```

---

## ðŸ§  4. Lazy vs Eager

### âš¡ Eager (par dÃ©faut)
Comme Pandas : chaque opÃ©ration exÃ©cute immÃ©diatement.

```python
df = pl.read_csv("flights.csv")
df.filter(pl.col("delay") > 15).select("airline")
```

### ðŸ’¤ Lazy (optimisÃ© avant exÃ©cution)

```python
lazy_df = pl.read_csv("flights.csv").lazy()
result = (
    lazy_df
    .filter(pl.col("delay") > 15)
    .groupby("airline")
    .agg(pl.mean("delay"))
    .sort("delay", descending=True)
    .collect()  # âš ï¸ ne calcule qu'ici
)
```

Avantages :
- Optimisations automatiques : projection pushdown, filtre pushdown, etc.
- ExÃ©cution en un seul plan de calcul

---

## âš¡ 5. Comparatif de perfs (vs Pandas)

| OpÃ©ration         | Pandas (1M rows) | Polars eager | Polars lazy |
|-------------------|------------------|--------------|-------------|
| CSV load          | ~1.2s            | ~0.4s        | ~0.4s       |
| GroupBy + Mean    | ~0.7s            | ~0.2s        | ~0.05s      |
| Filter + Sort     | ~0.5s            | ~0.1s        | ~0.03s      |
| RAM utilisÃ©e      | Ã©levÃ©e           | basse        | basse       |

---

## ðŸ§¬ 6. Comparaison API Pandas vs Polars

| Action                   | Pandas                             | Polars                               |
|--------------------------|------------------------------------|--------------------------------------|
| SÃ©lection conditionnelle | `df[df["x"] > 0]`                  | `df.filter(pl.col("x") > 0)`         |
| GroupBy + agg            | `df.groupby("x")["y"].mean()`      | `df.groupby("x").agg(pl.mean("y"))`  |
| Renommage                | `df.rename(columns={"a": "b"})`    | `df.rename({"a": "b"})`              |
| Fusion (merge)           | `df.merge(df2, on="id")`           | `df.join(df2, on="id")`              |

---

## ðŸ“¦ 7. Polars & fichiers

- `pl.read_csv("file.csv")`
- `pl.read_parquet("data.parquet")`
- `df.write_csv("out.csv")`
- `df.write_parquet("out.parquet")`

Prise en charge native de :
- CSV / TSV
- Parquet
- IPC / Arrow

---

## ðŸ§ª 8. InteropÃ©rabilitÃ©

- Polars peut convertir vers Pandas : `df.to_pandas()`
- Ou depuis Pandas : `pl.from_pandas(df)`
- Compatible avec NumPy via `.to_numpy()`, `pl.Series("x", np_array)`

---

## ðŸ§  9. Cas dâ€™usage idÃ©aux

- Traitement de **trÃ¨s gros fichiers**
- Pipelines **data engineering**
- Scripts **multithread** sans effort
- Remplacer Spark localement pour jobs de transformation
- Traitement de logs, NDJSON, donnÃ©es tabulaires lourdes

---

## ðŸ“Œ 10. En rÃ©sumÃ©

| Tu veux...                                        | Utilise...     |
|--------------------------------------------------|----------------|
| IntÃ©gration facile avec SciPy, Matplotlib, etc.  | Pandas         |
| Performance + faible RAM + multi-thread          | Polars         |
| Pipelines scalables avec transformations         | Polars (lazy)  |
| Manipulation interactive en notebook             | Pandas ou Polars (eager) |

---

On entre dans le domaine du **web scraping HTML**, 
tr√®s utile pour collecter automatiquement des donn√©es non disponibles via API ‚Äî par exemple : horaires de vols, prix de billets, infos compagnies, etc.

---

## üß∞ Les librairies Python les plus utilis√©es pour le scraping

| Librairie | Type | Points forts | Cas d‚Äôusage |
|----------|------|---------------|-------------|
| **`requests`** | HTTP | Simple pour r√©cup√©rer les pages | T√©l√©chargement HTML brut |
| **`BeautifulSoup`** (`bs4`) | Parsing | Ultra lisible, parsing HTML/XML | Extraire du contenu balis√© |
| **`lxml`** | Parsing (rapide) | Tr√®s rapide, support XPath | Structure complexe |
| **`Selenium`** | Navigateur headless | Pour les pages JS, simulateur humain | Scraper des sites dynamiques |
| **`Playwright`** | Navigateur moderne | Alternative + rapide √† Selenium | JS lourd, interactions complexes |
| **`Scrapy`** | Framework complet | Scraping massif, pipeline int√©gr√© | Projets structur√©s / crawl en masse |

---

## ‚úàÔ∏è Exemple simple (horaires de vols, BeautifulSoup)

Imaginons qu‚Äôon scrape une page HTML qui contient √ßa :

```html
<div class="flight">
  <span class="flight-number">AF123</span>
  <span class="departure">CDG</span>
  <span class="arrival">JFK</span>
  <span class="time">10:45</span>
</div>
```

### üìú Code avec `requests` + `BeautifulSoup`

```python
import requests
from bs4 import BeautifulSoup

url = "https://example.com/flights-today"
response = requests.get(url)
soup = BeautifulSoup(response.text, "html.parser")

flights = []

for flight in soup.select(".flight"):
    number = flight.select_one(".flight-number").text.strip()
    departure = flight.select_one(".departure").text.strip()
    arrival = flight.select_one(".arrival").text.strip()
    time = flight.select_one(".time").text.strip()
    
    flights.append({
        "number": number,
        "departure": departure,
        "arrival": arrival,
        "time": time
    })

print(flights)
```

---

## üîÑ Comparaison rapide des outils

| Outil | Simplicit√© | JS Support | Performance | Id√©al pour |
|-------|------------|------------|-------------|-------------|
| `requests + bs4` | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ùå | ‚úÖ‚úÖ‚úÖ | HTML statique |
| `lxml` | ‚≠ê‚≠ê‚≠ê | ‚ùå | ‚úÖ‚úÖ‚úÖ‚úÖ | HTML structur√©, XPath |
| `Selenium` | ‚≠ê‚≠ê | ‚úÖ‚úÖ‚úÖ | ‚ùå‚ùå | Sites interactifs JS |
| `Playwright` | ‚≠ê‚≠ê‚≠ê | ‚úÖ‚úÖ‚úÖ‚úÖ | ‚úÖ‚úÖ‚úÖ | Scraping JS moderne |
| `Scrapy` | ‚≠ê‚≠ê (setup) | üî∏ (via middlewares) | ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ | Crawling massif et structur√© |

---

## üöÄ Exemple plus avanc√© avec `Playwright`

```python
from playwright.sync_api import sync_playwright

with sync_playwright() as p:
    browser = p.chromium.launch(headless=True)
    page = browser.new_page()
    page.goto("https://example.com/flights")

    flights = page.query_selector_all(".flight")
    for f in flights:
        print(f.inner_text())

    browser.close()
```

> üëâ **Playwright** est tr√®s utile si le site charge les donn√©es **en JS apr√®s chargement**.

---

https://scrapeops.io/python-web-scraping-playbook/python-requests-beautifulsoup-beginners-guide/

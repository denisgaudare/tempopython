# âœ… Squelette de projet basÃ© sur `APScheduler`**, une solution robuste et modulaire pour **planifier des tÃ¢ches** (rÃ©currentes, uniques, diffÃ©rÃ©es, etc.) dans un script Python.

---

# ğŸ› ï¸ Worker Python avec `APScheduler`

## âš™ï¸ Avantages de `APScheduler`
- ğŸ” Planification simple de tÃ¢ches rÃ©currentes
- â± Support des jobs pÃ©riodiques, cron, ou datÃ©s
- ğŸ§© ExÃ©cution en background via ThreadPool
- ğŸ“¦ Persistable (SQLite, Redisâ€¦) si besoin

---

## ğŸ“ Arborescence

```
apscheduler_worker/
â”œâ”€â”€ worker.py
â”œâ”€â”€ monitor.py
â”œâ”€â”€ config.py
â”œâ”€â”€ tasks.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ logs/
    â””â”€â”€ apscheduler.log
```

---

## ğŸ“¦ `requirements.txt`

```txt
apscheduler
loguru
psutil
sentry-sdk
```

---

## âš™ï¸ `config.py`

```python
import os

LOG_PATH = os.getenv("LOG_PATH", "logs/apscheduler.log")
SENTRY_DSN = os.getenv("SENTRY_DSN", "")
```

---

## ğŸ“‹ `monitor.py`

```python
from loguru import logger
import psutil
import sentry_sdk
from config import LOG_PATH, SENTRY_DSN

# Logger configurÃ©
logger.add(LOG_PATH, rotation="1 MB", retention="7 days", level="INFO")

# Sentry
if SENTRY_DSN:
    sentry_sdk.init(dsn=SENTRY_DSN)

def log_resources():
    process = psutil.Process()
    mem = process.memory_info().rss / 1e6
    cpu = psutil.cpu_percent(interval=0.1)
    logger.debug(f"[RESOURCES] RAM: {mem:.2f} MB | CPU: {cpu}%")

def monitor_exceptions(fn):
    def wrapper(*args, **kwargs):
        try:
            return fn(*args, **kwargs)
        except Exception as e:
            logger.exception("Erreur dans la tÃ¢che")
            sentry_sdk.capture_exception(e)
            raise
    return wrapper
```

---

## ğŸ§  `tasks.py`

```python
import time
from monitor import logger, log_resources, monitor_exceptions

@monitor_exceptions
def scheduled_job():
    logger.info("ğŸ”§ TÃ¢che planifiÃ©e dÃ©marrÃ©e")
    log_resources()
    time.sleep(2)  # Simule un traitement
    logger.info("âœ… TÃ¢che terminÃ©e")
```

---

## ğŸ”„ `worker.py`

```python
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.executors.pool import ThreadPoolExecutor
from tasks import scheduled_job
from monitor import logger
import time

if __name__ == "__main__":
    logger.info("=== APScheduler Worker dÃ©marrÃ© ===")

    # Configuration du scheduler
    scheduler = BackgroundScheduler(
        executors={'default': ThreadPoolExecutor(4)},
        job_defaults={'coalesce': False, 'max_instances': 2}
    )

    # Ajouter une tÃ¢che toutes les 10 secondes
    scheduler.add_job(scheduled_job, 'interval', seconds=10, id='main_job')

    # DÃ©marrer le scheduler
    scheduler.start()

    try:
        while True:
            time.sleep(1)  # Main thread reste vivant
    except (KeyboardInterrupt, SystemExit):
        logger.info("ArrÃªt demandÃ©. Shutdown du scheduler.")
        scheduler.shutdown()
```

---

## âœ… FonctionnalitÃ©s incluses

| FonctionnalitÃ©                    | Inclus |
|----------------------------------|--------|
| Logging structurÃ©                | âœ…     |
| Monitoring CPU/RAM               | âœ…     |
| Gestion dâ€™erreurs avec Sentry    | âœ…     |
| TÃ¢che planifiÃ©e toutes les X sec | âœ…     |
| ThreadPool pour multitÃ¢che       | âœ…     |
| Gestion des erreurs isolÃ©e par tÃ¢che | âœ… |

---

## ğŸ§ª Bonus : autres types de tÃ¢ches possibles

```python
# TÃ¢che Ã  une date prÃ©cise
scheduler.add_job(scheduled_job, 'date', run_date='2025-03-22 14:00:00')

# TÃ¢che style cron (ex: tous les lundis Ã  8h)
scheduler.add_job(scheduled_job, 'cron', day_of_week='mon', hour=8, minute=0)
```

---

Souhaites-tu une version avec **persistance en base (SQLite ou Redis)** pour que les tÃ¢ches survivent au redÃ©marrage ? Ou quâ€™on intÃ¨gre des **metrics Prometheus** ou un dashboard Grafana ?